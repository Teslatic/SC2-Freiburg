<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Ghost: Agency.BaseAgent Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Ghost
   &#160;<span id="projectnumber">0.1</span>
   </div>
   <div id="projectbrief">A reinforcement learning approach on SC2</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceAgency.html">Agency</a></li><li class="navelem"><a class="el" href="classAgency_1_1BaseAgent.html">BaseAgent</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pri-methods">Private Member Functions</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="classAgency_1_1BaseAgent-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">Agency.BaseAgent Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Documentation for <a class="el" href="classAgency_1_1BaseAgent.html" title="Documentation for BaseAgent. ">BaseAgent</a>.  
 <a href="classAgency_1_1BaseAgent.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for Agency.BaseAgent:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classAgency_1_1BaseAgent.png" usemap="#Agency.BaseAgent_map" alt=""/>
  <map id="Agency.BaseAgent_map" name="Agency.BaseAgent_map">
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a8000d3852f7eada76fd862a036e8c5ac"><td class="memItemLeft" align="right" valign="top"><a id="a8000d3852f7eada76fd862a036e8c5ac"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a8000d3852f7eada76fd862a036e8c5ac">__init__</a> (self, architecture, FLAGS, device=&quot;cpu&quot;)</td></tr>
<tr class="memdesc:a8000d3852f7eada76fd862a036e8c5ac"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor. <br /></td></tr>
<tr class="separator:a8000d3852f7eada76fd862a036e8c5ac"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a387d924de5e98fc7e87e5750ffbc8116"><td class="memItemLeft" align="right" valign="top"><a id="a387d924de5e98fc7e87e5750ffbc8116"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a387d924de5e98fc7e87e5750ffbc8116">log_reward</a> (self)</td></tr>
<tr class="memdesc:a387d924de5e98fc7e87e5750ffbc8116"><td class="mdescLeft">&#160;</td><td class="mdescRight">logs rewards per epochs and cumulative reward in a csv file <br /></td></tr>
<tr class="separator:a387d924de5e98fc7e87e5750ffbc8116"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a901aab539081be07996dca97de2f2e06"><td class="memItemLeft" align="right" valign="top"><a id="a901aab539081be07996dca97de2f2e06"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a901aab539081be07996dca97de2f2e06">decide</a> (self)</td></tr>
<tr class="memdesc:a901aab539081be07996dca97de2f2e06"><td class="mdescLeft">&#160;</td><td class="mdescRight">determins if the next action is goint to be random or greedy <br /></td></tr>
<tr class="separator:a901aab539081be07996dca97de2f2e06"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1f7d1b84d919eb3d2ce9092ad2161d1b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a1f7d1b84d919eb3d2ce9092ad2161d1b">choose_action</a> (self)</td></tr>
<tr class="memdesc:a1f7d1b84d919eb3d2ce9092ad2161d1b"><td class="mdescLeft">&#160;</td><td class="mdescRight">chooses the next action  <a href="#a1f7d1b84d919eb3d2ce9092ad2161d1b">More...</a><br /></td></tr>
<tr class="separator:a1f7d1b84d919eb3d2ce9092ad2161d1b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06cd034442fe41432486654dfafa0937"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a06cd034442fe41432486654dfafa0937">extract_action</a> (self)</td></tr>
<tr class="memdesc:a06cd034442fe41432486654dfafa0937"><td class="mdescLeft">&#160;</td><td class="mdescRight">extracts the action from the list of available actions in the actual game  <a href="#a06cd034442fe41432486654dfafa0937">More...</a><br /></td></tr>
<tr class="separator:a06cd034442fe41432486654dfafa0937"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a59f2f9a055e2c145bc83f610e26b8096"><td class="memItemLeft" align="right" valign="top"><a id="a59f2f9a055e2c145bc83f610e26b8096"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a59f2f9a055e2c145bc83f610e26b8096">step</a> (self)</td></tr>
<tr class="memdesc:a59f2f9a055e2c145bc83f610e26b8096"><td class="mdescLeft">&#160;</td><td class="mdescRight">invokes one agent step by starting the pipeline to acquire the next action <br /></td></tr>
<tr class="separator:a59f2f9a055e2c145bc83f610e26b8096"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a663f1d2913fa6a467077a55ddf854dae"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a663f1d2913fa6a467077a55ddf854dae">calc_pseudo_reward</a> (self)</td></tr>
<tr class="memdesc:a663f1d2913fa6a467077a55ddf854dae"><td class="mdescLeft">&#160;</td><td class="mdescRight">calculate a pseudo reward in order to handle sparse rewards  <a href="#a663f1d2913fa6a467077a55ddf854dae">More...</a><br /></td></tr>
<tr class="separator:a663f1d2913fa6a467077a55ddf854dae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adef4f441aa6cbd1f3bb2c85839b9f403"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#adef4f441aa6cbd1f3bb2c85839b9f403">optimize</a> (self)</td></tr>
<tr class="memdesc:adef4f441aa6cbd1f3bb2c85839b9f403"><td class="mdescLeft">&#160;</td><td class="mdescRight">optimizes the network and updates the target network every _target_net_udpdate episodes  <a href="#adef4f441aa6cbd1f3bb2c85839b9f403">More...</a><br /></td></tr>
<tr class="separator:adef4f441aa6cbd1f3bb2c85839b9f403"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9cb7dd560c63c2fe8d1967568b6a82ed"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a9cb7dd560c63c2fe8d1967568b6a82ed">print_status</a> (self)</td></tr>
<tr class="memdesc:a9cb7dd560c63c2fe8d1967568b6a82ed"><td class="mdescLeft">&#160;</td><td class="mdescRight">prints some status infos, e.g.  <a href="#a9cb7dd560c63c2fe8d1967568b6a82ed">More...</a><br /></td></tr>
<tr class="separator:a9cb7dd560c63c2fe8d1967568b6a82ed"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa06a4883d4637c0fdfca1d8d37f94069"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#aa06a4883d4637c0fdfca1d8d37f94069">play</a> (self)</td></tr>
<tr class="memdesc:aa06a4883d4637c0fdfca1d8d37f94069"><td class="mdescLeft">&#160;</td><td class="mdescRight">training loop  <a href="#aa06a4883d4637c0fdfca1d8d37f94069">More...</a><br /></td></tr>
<tr class="separator:aa06a4883d4637c0fdfca1d8d37f94069"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:aac02c4ec3cb8092b0658a5016ca34da5"><td class="memItemLeft" align="right" valign="top"><a id="aac02c4ec3cb8092b0658a5016ca34da5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#aac02c4ec3cb8092b0658a5016ca34da5">epsilon</a></td></tr>
<tr class="memdesc:aac02c4ec3cb8092b0658a5016ca34da5"><td class="mdescLeft">&#160;</td><td class="mdescRight">epsilon, has to be initialized with 1.0 <br /></td></tr>
<tr class="separator:aac02c4ec3cb8092b0658a5016ca34da5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0fd91f1d7a6e98d7a595a10cca3971f6"><td class="memItemLeft" align="right" valign="top"><a id="a0fd91f1d7a6e98d7a595a10cca3971f6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a0fd91f1d7a6e98d7a595a10cca3971f6">total_reward</a></td></tr>
<tr class="memdesc:a0fd91f1d7a6e98d7a595a10cca3971f6"><td class="mdescLeft">&#160;</td><td class="mdescRight">total reward achieved in training (pysc2 reward) <br /></td></tr>
<tr class="separator:a0fd91f1d7a6e98d7a595a10cca3971f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1faa8d7c16f35e8b83a0e3ae176f59c"><td class="memItemLeft" align="right" valign="top"><a id="ad1faa8d7c16f35e8b83a0e3ae176f59c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#ad1faa8d7c16f35e8b83a0e3ae176f59c">r_per_epoch</a></td></tr>
<tr class="memdesc:ad1faa8d7c16f35e8b83a0e3ae176f59c"><td class="mdescLeft">&#160;</td><td class="mdescRight">array to kreep track of the reward per epoch <br /></td></tr>
<tr class="separator:ad1faa8d7c16f35e8b83a0e3ae176f59c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a07b769c1dc93900667c4fa575e78a2"><td class="memItemLeft" align="right" valign="top"><a id="a1a07b769c1dc93900667c4fa575e78a2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a1a07b769c1dc93900667c4fa575e78a2">list_score_cumulative</a></td></tr>
<tr class="memdesc:a1a07b769c1dc93900667c4fa575e78a2"><td class="mdescLeft">&#160;</td><td class="mdescRight">list to keep track of the cumulative score <br /></td></tr>
<tr class="separator:a1a07b769c1dc93900667c4fa575e78a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa35d9fa21795e21339570f483d99b56c"><td class="memItemLeft" align="right" valign="top"><a id="aa35d9fa21795e21339570f483d99b56c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#aa35d9fa21795e21339570f483d99b56c">memory</a></td></tr>
<tr class="memdesc:aa35d9fa21795e21339570f483d99b56c"><td class="mdescLeft">&#160;</td><td class="mdescRight">initializing of the <a class="el" href="classAgency_1_1ReplayBuffer.html" title="Documentation for ReplayBuffer. ">ReplayBuffer</a> <br /></td></tr>
<tr class="separator:aa35d9fa21795e21339570f483d99b56c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adcc438ca0e3c70602fc3fd8941380dfd"><td class="memItemLeft" align="right" valign="top"><a id="adcc438ca0e3c70602fc3fd8941380dfd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#adcc438ca0e3c70602fc3fd8941380dfd">action_idx</a></td></tr>
<tr class="memdesc:adcc438ca0e3c70602fc3fd8941380dfd"><td class="mdescLeft">&#160;</td><td class="mdescRight">the index of the x,y pair that is chosen <br /></td></tr>
<tr class="separator:adcc438ca0e3c70602fc3fd8941380dfd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a72269503c3be981fe59c51e6f46563c2"><td class="memItemLeft" align="right" valign="top"><a id="a72269503c3be981fe59c51e6f46563c2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a72269503c3be981fe59c51e6f46563c2">action_xy</a></td></tr>
<tr class="memdesc:a72269503c3be981fe59c51e6f46563c2"><td class="mdescLeft">&#160;</td><td class="mdescRight">the actual x,y pair which will be used in the next action <br /></td></tr>
<tr class="separator:a72269503c3be981fe59c51e6f46563c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ac4296207527be00adc988fa95af709"><td class="memItemLeft" align="right" valign="top"><a id="a7ac4296207527be00adc988fa95af709"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a7ac4296207527be00adc988fa95af709">pysc_action</a></td></tr>
<tr class="memdesc:a7ac4296207527be00adc988fa95af709"><td class="mdescLeft">&#160;</td><td class="mdescRight">the action id of the pysc2 action, necessary to extract the real action <br /></td></tr>
<tr class="separator:a7ac4296207527be00adc988fa95af709"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1ef5401d902e7e79853793e386d80c5"><td class="memItemLeft" align="right" valign="top"><a id="ab1ef5401d902e7e79853793e386d80c5"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#ab1ef5401d902e7e79853793e386d80c5">action</a></td></tr>
<tr class="memdesc:ab1ef5401d902e7e79853793e386d80c5"><td class="mdescLeft">&#160;</td><td class="mdescRight">the actual action which is used by the pysc2 enginge <br /></td></tr>
<tr class="separator:ab1ef5401d902e7e79853793e386d80c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abeb097dc014891c983b8cb5b993cb624"><td class="memItemLeft" align="right" valign="top"><a id="abeb097dc014891c983b8cb5b993cb624"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#abeb097dc014891c983b8cb5b993cb624">actual_obs</a></td></tr>
<tr class="memdesc:abeb097dc014891c983b8cb5b993cb624"><td class="mdescLeft">&#160;</td><td class="mdescRight">verbose state observation <br /></td></tr>
<tr class="separator:abeb097dc014891c983b8cb5b993cb624"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1ba1f291bc8f4360668c8e02186f83a"><td class="memItemLeft" align="right" valign="top"><a id="ad1ba1f291bc8f4360668c8e02186f83a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#ad1ba1f291bc8f4360668c8e02186f83a">state</a></td></tr>
<tr class="memdesc:ad1ba1f291bc8f4360668c8e02186f83a"><td class="mdescLeft">&#160;</td><td class="mdescRight">state tensor <br /></td></tr>
<tr class="separator:ad1ba1f291bc8f4360668c8e02186f83a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a27248be7da0c8a830b7a7e60a4c96344"><td class="memItemLeft" align="right" valign="top"><a id="a27248be7da0c8a830b7a7e60a4c96344"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a27248be7da0c8a830b7a7e60a4c96344">next_obs</a></td></tr>
<tr class="memdesc:a27248be7da0c8a830b7a7e60a4c96344"><td class="mdescLeft">&#160;</td><td class="mdescRight">next_obs is the next state but densely encoded by the pysc2 engine <br /></td></tr>
<tr class="separator:a27248be7da0c8a830b7a7e60a4c96344"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a63181f746aea31b031c03050f2c4996f"><td class="memItemLeft" align="right" valign="top"><a id="a63181f746aea31b031c03050f2c4996f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a63181f746aea31b031c03050f2c4996f">next_state</a></td></tr>
<tr class="memdesc:a63181f746aea31b031c03050f2c4996f"><td class="mdescLeft">&#160;</td><td class="mdescRight">next_state is the more verbose version of next_obs and also used by the network <br /></td></tr>
<tr class="separator:a63181f746aea31b031c03050f2c4996f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-methods"></a>
Private Member Functions</h2></td></tr>
<tr class="memitem:a7b6427b6a1ddf05110a588cbbcc7592b"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a7b6427b6a1ddf05110a588cbbcc7592b">_build_model</a> (self, architecture)</td></tr>
<tr class="memdesc:a7b6427b6a1ddf05110a588cbbcc7592b"><td class="mdescLeft">&#160;</td><td class="mdescRight">construct the network, the target network and the optimizer  <a href="#a7b6427b6a1ddf05110a588cbbcc7592b">More...</a><br /></td></tr>
<tr class="separator:a7b6427b6a1ddf05110a588cbbcc7592b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac965ebdc21d12c9a39ce8e2b75f1c5b8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#ac965ebdc21d12c9a39ce8e2b75f1c5b8">_build_env</a> (self)</td></tr>
<tr class="memdesc:ac965ebdc21d12c9a39ce8e2b75f1c5b8"><td class="mdescLeft">&#160;</td><td class="mdescRight">construct the pysc2 environment in order to make the SC2 engine playable by the agent  <a href="#ac965ebdc21d12c9a39ce8e2b75f1c5b8">More...</a><br /></td></tr>
<tr class="separator:ac965ebdc21d12c9a39ce8e2b75f1c5b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7f90b138b07e8667a2fefd8f79e9b749"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a7f90b138b07e8667a2fefd8f79e9b749">_discretize_xy_grid</a> (self, factor)</td></tr>
<tr class="memdesc:a7f90b138b07e8667a2fefd8f79e9b749"><td class="mdescLeft">&#160;</td><td class="mdescRight">"discretizes" the x,y coordinate system into smaller parts in order to keep the action space smaller  <a href="#a7f90b138b07e8667a2fefd8f79e9b749">More...</a><br /></td></tr>
<tr class="separator:a7f90b138b07e8667a2fefd8f79e9b749"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad0c1c3971f99373113ccfcb68f55ce61"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#ad0c1c3971f99373113ccfcb68f55ce61">_xy_locs</a> (self, mask)</td></tr>
<tr class="memdesc:ad0c1c3971f99373113ccfcb68f55ce61"><td class="mdescLeft">&#160;</td><td class="mdescRight">returns the xy location of a given game-object, like a marine for example  <a href="#ad0c1c3971f99373113ccfcb68f55ce61">More...</a><br /></td></tr>
<tr class="separator:ad0c1c3971f99373113ccfcb68f55ce61"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a101857f27c887a9599d064f582e58bfc"><td class="memItemLeft" align="right" valign="top"><a id="a101857f27c887a9599d064f582e58bfc"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a101857f27c887a9599d064f582e58bfc">_save_model</a> (self)</td></tr>
<tr class="memdesc:a101857f27c887a9599d064f582e58bfc"><td class="mdescLeft">&#160;</td><td class="mdescRight">saves the pytorch model <br /></td></tr>
<tr class="separator:a101857f27c887a9599d064f582e58bfc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:aa9c49bc30c7714e60240621fa842c48f"><td class="memItemLeft" align="right" valign="top"><a id="aa9c49bc30c7714e60240621fa842c48f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#aa9c49bc30c7714e60240621fa842c48f">_name</a></td></tr>
<tr class="memdesc:aa9c49bc30c7714e60240621fa842c48f"><td class="mdescLeft">&#160;</td><td class="mdescRight">name of the experiment <br /></td></tr>
<tr class="separator:aa9c49bc30c7714e60240621fa842c48f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a942e0ae66a7f7382a1176e49729979d1"><td class="memItemLeft" align="right" valign="top"><a id="a942e0ae66a7f7382a1176e49729979d1"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a942e0ae66a7f7382a1176e49729979d1">_path</a></td></tr>
<tr class="memdesc:a942e0ae66a7f7382a1176e49729979d1"><td class="mdescLeft">&#160;</td><td class="mdescRight">where to save model and reward csv <br /></td></tr>
<tr class="separator:a942e0ae66a7f7382a1176e49729979d1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af61223f2986231e1ffc18b5ee1c58d4a"><td class="memItemLeft" align="right" valign="top"><a id="af61223f2986231e1ffc18b5ee1c58d4a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#af61223f2986231e1ffc18b5ee1c58d4a">_lr</a></td></tr>
<tr class="memdesc:af61223f2986231e1ffc18b5ee1c58d4a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Learning rate for the optimizer. <br /></td></tr>
<tr class="separator:af61223f2986231e1ffc18b5ee1c58d4a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af1ed6712db1813e675955005c17bade6"><td class="memItemLeft" align="right" valign="top"><a id="af1ed6712db1813e675955005c17bade6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#af1ed6712db1813e675955005c17bade6">_gamma</a></td></tr>
<tr class="memdesc:af1ed6712db1813e675955005c17bade6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Discount factor. <br /></td></tr>
<tr class="separator:af1ed6712db1813e675955005c17bade6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a247146182d23b3ada0a4e851bedd3c37"><td class="memItemLeft" align="right" valign="top"><a id="a247146182d23b3ada0a4e851bedd3c37"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a247146182d23b3ada0a4e851bedd3c37">_batch_size</a></td></tr>
<tr class="memdesc:a247146182d23b3ada0a4e851bedd3c37"><td class="mdescLeft">&#160;</td><td class="mdescRight">Batch size. <br /></td></tr>
<tr class="separator:a247146182d23b3ada0a4e851bedd3c37"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa98b4697dd1efc2617cdff5a6f0a76a6"><td class="memItemLeft" align="right" valign="top"><a id="aa98b4697dd1efc2617cdff5a6f0a76a6"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#aa98b4697dd1efc2617cdff5a6f0a76a6">_target_update</a></td></tr>
<tr class="memdesc:aa98b4697dd1efc2617cdff5a6f0a76a6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update the target network every N epochs. <br /></td></tr>
<tr class="separator:aa98b4697dd1efc2617cdff5a6f0a76a6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae50cf15d8a8e27257ebfc147109eee71"><td class="memItemLeft" align="right" valign="top"><a id="ae50cf15d8a8e27257ebfc147109eee71"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#ae50cf15d8a8e27257ebfc147109eee71">_epochs</a></td></tr>
<tr class="memdesc:ae50cf15d8a8e27257ebfc147109eee71"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of epochs to train. <br /></td></tr>
<tr class="separator:ae50cf15d8a8e27257ebfc147109eee71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaae52ad633814dfe257eed442f5f4b7e"><td class="memItemLeft" align="right" valign="top"><a id="aaae52ad633814dfe257eed442f5f4b7e"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#aaae52ad633814dfe257eed442f5f4b7e">_memory_size</a></td></tr>
<tr class="memdesc:aaae52ad633814dfe257eed442f5f4b7e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Replay Buffer capacity. <br /></td></tr>
<tr class="separator:aaae52ad633814dfe257eed442f5f4b7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0c5ff3459c502c25ed79b01c9d779b63"><td class="memItemLeft" align="right" valign="top"><a id="a0c5ff3459c502c25ed79b01c9d779b63"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a0c5ff3459c502c25ed79b01c9d779b63">_visualize</a></td></tr>
<tr class="memdesc:a0c5ff3459c502c25ed79b01c9d779b63"><td class="mdescLeft">&#160;</td><td class="mdescRight">Set to true to see actual game screen. <br /></td></tr>
<tr class="separator:a0c5ff3459c502c25ed79b01c9d779b63"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a81e91b00ec8d40d267f39dbbd3c4a1d3"><td class="memItemLeft" align="right" valign="top"><a id="a81e91b00ec8d40d267f39dbbd3c4a1d3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a81e91b00ec8d40d267f39dbbd3c4a1d3">_device</a></td></tr>
<tr class="memdesc:a81e91b00ec8d40d267f39dbbd3c4a1d3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train on GPU or CPU, default is GPU if available. <br /></td></tr>
<tr class="separator:a81e91b00ec8d40d267f39dbbd3c4a1d3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76d7d38e700e7d5a3da83bf2c3237856"><td class="memItemLeft" align="right" valign="top"><a id="a76d7d38e700e7d5a3da83bf2c3237856"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a76d7d38e700e7d5a3da83bf2c3237856">_map_name</a></td></tr>
<tr class="memdesc:a76d7d38e700e7d5a3da83bf2c3237856"><td class="mdescLeft">&#160;</td><td class="mdescRight">Name of the scneario/map. <br /></td></tr>
<tr class="separator:a76d7d38e700e7d5a3da83bf2c3237856"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefe924af6e56114594a6254df8ec0253"><td class="memItemLeft" align="right" valign="top"><a id="aefe924af6e56114594a6254df8ec0253"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#aefe924af6e56114594a6254df8ec0253">_step_multiplier</a></td></tr>
<tr class="memdesc:aefe924af6e56114594a6254df8ec0253"><td class="mdescLeft">&#160;</td><td class="mdescRight">How many game steps per agent step. <br /></td></tr>
<tr class="separator:aefe924af6e56114594a6254df8ec0253"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a001079ac67514da6784c687313065cea"><td class="memItemLeft" align="right" valign="top"><a id="a001079ac67514da6784c687313065cea"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a001079ac67514da6784c687313065cea">_eps_decay</a></td></tr>
<tr class="memdesc:a001079ac67514da6784c687313065cea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Epsilon decay rate; high -&gt; slow decay. <br /></td></tr>
<tr class="separator:a001079ac67514da6784c687313065cea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a1ba863a11e4295203cadf4abcfeac3"><td class="memItemLeft" align="right" valign="top"><a id="a1a1ba863a11e4295203cadf4abcfeac3"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a1a1ba863a11e4295203cadf4abcfeac3">_EPS_START</a></td></tr>
<tr class="memdesc:a1a1ba863a11e4295203cadf4abcfeac3"><td class="mdescLeft">&#160;</td><td class="mdescRight">start value for epsilon decay <br /></td></tr>
<tr class="separator:a1a1ba863a11e4295203cadf4abcfeac3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad93eb985739706f8a17842953fda2d9c"><td class="memItemLeft" align="right" valign="top"><a id="ad93eb985739706f8a17842953fda2d9c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#ad93eb985739706f8a17842953fda2d9c">_EPS_END</a></td></tr>
<tr class="memdesc:ad93eb985739706f8a17842953fda2d9c"><td class="mdescLeft">&#160;</td><td class="mdescRight">end value for epsilon decay <br /></td></tr>
<tr class="separator:ad93eb985739706f8a17842953fda2d9c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c1c2888e59101190c71795031e89b6c"><td class="memItemLeft" align="right" valign="top"><a id="a3c1c2888e59101190c71795031e89b6c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a3c1c2888e59101190c71795031e89b6c">_steps_done</a></td></tr>
<tr class="memdesc:a3c1c2888e59101190c71795031e89b6c"><td class="mdescLeft">&#160;</td><td class="mdescRight">step counter for epsilon calculation <br /></td></tr>
<tr class="separator:a3c1c2888e59101190c71795031e89b6c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aed81b1c10d3a9efe5e98d0e15fd72a8f"><td class="memItemLeft" align="right" valign="top"><a id="aed81b1c10d3a9efe5e98d0e15fd72a8f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#aed81b1c10d3a9efe5e98d0e15fd72a8f">_choice</a></td></tr>
<tr class="memdesc:aed81b1c10d3a9efe5e98d0e15fd72a8f"><td class="mdescLeft">&#160;</td><td class="mdescRight">displays choice: random or greed, init with None <br /></td></tr>
<tr class="separator:aed81b1c10d3a9efe5e98d0e15fd72a8f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b87389e4d22e2272d198de09114faff"><td class="memItemLeft" align="right" valign="top"><a id="a0b87389e4d22e2272d198de09114faff"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a0b87389e4d22e2272d198de09114faff">_SMART_ACTIONS</a></td></tr>
<tr class="memdesc:a0b87389e4d22e2272d198de09114faff"><td class="mdescLeft">&#160;</td><td class="mdescRight">actions available to the agent, chosen by design <br /></td></tr>
<tr class="separator:a0b87389e4d22e2272d198de09114faff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7809a1ed065d25c9c414b0a1176211d2"><td class="memItemLeft" align="right" valign="top"><a id="a7809a1ed065d25c9c414b0a1176211d2"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a7809a1ed065d25c9c414b0a1176211d2">_optimizer</a></td></tr>
<tr class="memdesc:a7809a1ed065d25c9c414b0a1176211d2"><td class="mdescLeft">&#160;</td><td class="mdescRight">setting up the network, target network and optimizer <br /></td></tr>
<tr class="separator:a7809a1ed065d25c9c414b0a1176211d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a600366eed556fa0c9d077ae5635c244a"><td class="memItemLeft" align="right" valign="top"><a id="a600366eed556fa0c9d077ae5635c244a"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a600366eed556fa0c9d077ae5635c244a">_env</a></td></tr>
<tr class="memdesc:a600366eed556fa0c9d077ae5635c244a"><td class="mdescLeft">&#160;</td><td class="mdescRight">initializing the pysc2 environment in order to play SC2 <br /></td></tr>
<tr class="separator:a600366eed556fa0c9d077ae5635c244a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a114098d693d23c2b6024bff9ab4e3c"><td class="memItemLeft" align="right" valign="top"><a id="a9a114098d693d23c2b6024bff9ab4e3c"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classAgency_1_1BaseAgent.html#a9a114098d693d23c2b6024bff9ab4e3c">_xy_pairs</a></td></tr>
<tr class="memdesc:a9a114098d693d23c2b6024bff9ab4e3c"><td class="mdescLeft">&#160;</td><td class="mdescRight">initializing the x,y coordinate pairs available to the agent <br /></td></tr>
<tr class="separator:a9a114098d693d23c2b6024bff9ab4e3c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This is the central agent which controls all program flow comprising:</p><ul>
<li>parsing flags to hyperparameter member variables</li>
<li>building the net, target net and optimizer</li>
<li>setting up the pysc2 environment in order to use it</li>
<li>playing</li>
<li>training</li>
<li>optimizing </li>
</ul>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00087">87</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="ac965ebdc21d12c9a39ce8e2b75f1c5b8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac965ebdc21d12c9a39ce8e2b75f1c5b8">&#9670;&nbsp;</a></span>_build_env()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent._build_env </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[out]</td><td class="paramname">env</td><td>pysc2 environment object </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00170">170</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="a7b6427b6a1ddf05110a588cbbcc7592b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b6427b6a1ddf05110a588cbbcc7592b">&#9670;&nbsp;</a></span>_build_model()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent._build_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>architecture</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">architecture</td><td>model object from architectures, chosen in main </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">net</td><td>feed forward neural network </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">target_net</td><td>feed forward neural target network </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">optimizer</td><td>Optimizer of choice, default is Adam </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00158">158</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="a7f90b138b07e8667a2fefd8f79e9b749"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7f90b138b07e8667a2fefd8f79e9b749">&#9670;&nbsp;</a></span>_discretize_xy_grid()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent._discretize_xy_grid </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>factor</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">factor</td><td>splits the total original x,y grid into factor^2 pairs </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">xy_space</td><td>array containing the discretized x,y coordinate pairs <pre class="fragment">"discretizing" action coordinates in order to keep action space small </pre> </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00191">191</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="ad0c1c3971f99373113ccfcb68f55ce61"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad0c1c3971f99373113ccfcb68f55ce61">&#9670;&nbsp;</a></span>_xy_locs()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent._xy_locs </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>mask</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">private</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">mask</td><td>Mask should be a set of bools from comparison with a feature layer </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">list(zip(x,y))</td><td>list of x,y coordinates where the object is located </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00205">205</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="a663f1d2913fa6a467077a55ddf854dae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a663f1d2913fa6a467077a55ddf854dae">&#9670;&nbsp;</a></span>calc_pseudo_reward()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent.calc_pseudo_reward </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>the actual reward of the pysc2 engine is very sparse. 0 for every step and 1 for the specific scenario reward, e.g. reaching a beacon. In order to make it easy for the agent, a pseudo reward is used. This reward is antiproportional to the distance from marine to beacon. Additionally, if the marine reaches the beacon a +10 is added to the reward.</p>
<p>This is only an intermediate step in order to find good first hyperparameters </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">beacon</td><td>x,y coordinates of the current beacon </td></tr>
    <tr><td class="paramname">marine_x</td><td>current x positon of the marine </td></tr>
    <tr><td class="paramname">marine_y</td><td>current y position of the marine </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00316">316</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="a1f7d1b84d919eb3d2ce9092ad2161d1b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1f7d1b84d919eb3d2ce9092ad2161d1b">&#9670;&nbsp;</a></span>choose_action()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent.choose_action </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>depends of the outcom of <a class="el" href="classAgency_1_1BaseAgent.html#a901aab539081be07996dca97de2f2e06" title="determins if the next action is goint to be random or greedy ">decide()</a>:</p><ul>
<li>random: from the list of _xy_pairs, one pair is chosen and applied to the move screeen action</li>
<li>greedy: current state is feedforwarded through the network and a x,y pair is picked according to the max q value </li>
</ul>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00250">250</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="a06cd034442fe41432486654dfafa0937"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a06cd034442fe41432486654dfafa0937">&#9670;&nbsp;</a></span>extract_action()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent.extract_action </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>the game needs specific encoded actions in order to work. These functions are too complicated for a network to handle, so the network would (in the later versions of the agent) pick numbers which are in turn ENUMS. According to the picked number, the unique action is applied</p>
<p>errorous action choices always result in NO_OP </p>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00285">285</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="adef4f441aa6cbd1f3bb2c85839b9f403"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adef4f441aa6cbd1f3bb2c85839b9f403">&#9670;&nbsp;</a></span>optimize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent.optimize </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>In this method, a batch is sampled from the <a class="el" href="classAgency_1_1ReplayBuffer.html" title="Documentation for ReplayBuffer. ">ReplayBuffer</a> memory and organized in its transition chunks:</p><ul>
<li>state_batch: batch of states</li>
<li>action_batch: batch of actions</li>
<li>reward_batch: batch of rewards</li>
<li>next_states: batch of next states</li>
</ul>
<p>The optimize method takes the batches and computes q values with the actual net and q values for the next states via the target network. Afterwards, the td target is calculated and used to get the loss between the actual q values and the td target </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[out]</td><td class="paramname">loss</td><td>current loss value computed by the opzimizer </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00365">365</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="aa06a4883d4637c0fdfca1d8d37f94069"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa06a4883d4637c0fdfca1d8d37f94069">&#9670;&nbsp;</a></span>play()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent.play </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>the play method is the actual training loop </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">state</td><td>tensor, where the current screen state is saved (player relative at the moment). The state has the dimensions (batch_size x 1 x 84 x 84) </td></tr>
    <tr><td class="paramname">next_state</td><td>same as state but for the next state </td></tr>
    <tr><td class="paramname">reward</td><td>tensor, containting the current reward </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00416">416</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<a id="a9cb7dd560c63c2fe8d1967568b6a82ed"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9cb7dd560c63c2fe8d1967568b6a82ed">&#9670;&nbsp;</a></span>print_status()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def Agency.BaseAgent.print_status </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<p>reward, episode, etc. </p>

<p class="definition">Definition at line <a class="el" href="Agency_8py_source.html#l00398">398</a> of file <a class="el" href="Agency_8py_source.html">Agency.py</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="Agency_8py_source.html">Agency.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
